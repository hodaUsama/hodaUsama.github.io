---
layout: post
title: "Understanding Independence and Bayesâ€™ Rule"
date: 2025-05-16
categories: [statistics,Descriptive statistics, beginner]
tags: [independence, bayes, conditional, tree-diagram, posterior, prior, likelihood]
math: true
description: Learn how Bayesâ€™ Theorem works, when to apply it, and how it connects to independence and conditional probability. This post breaks down key concepts with clear examples and practical relevance in real-world applications like spam detection and medical testing.

---

Understanding uncertainty is at the heart of statistics â€” and **Bayesâ€™ Rule** is one of the most powerful tools to deal with it.
This post will show you how Bayes' Theorem helps us update probabilities with new information, and how it connects to **independence, conditional probability,** and real-world reasoning â€” from medical diagnoses to machine learning models.
---

<div class="series-nav">
  <p>ğŸ“š <strong>This post is part of the "Intro to Statistics" series</strong></p>
  <p>ğŸ”™ <strong>Previously:</strong> <a href="/posts/union-conditional/">Making Sense of Union, Tables, and Conditional Thinking</a></p>
  <p>ğŸ”œ <strong>Next:</strong> <a href="/posts/Probabilities/">Probability Distributions & Cumulative Thinking</a></p>
</div>

---

## ğŸ”— <span style="color:#1E90FF;">What Is Independence?</span>

Two events are **independent** when the occurrence of one **doesnâ€™t affect** the probability of the other.

### ğŸ“Œ Mathematically:

Any of the following implies independence:

\\[
P(A \mid B) = P(A)
\\]
\\[
P(B \mid A) = P(B)
\\]
\\[
P(A \cap B) = P(A) \cdot P(B)
\\]

If **any** of these holds, the events are independent.

---

## ğŸ”„ <span style="color:#FFA500;">Independence vs Disjoint</span>

| Concept                           | Description                                       |
| --------------------------------- | ------------------------------------------------- |
| **Disjoint (Mutually Exclusive)** | Events canâ€™t both happen. \\( P(A \cap B) = 0 \\) |
| **Independent**                   | One event doesnâ€™t affect the otherâ€™s probability  |

### âœ… Key Insight:
- If A and B are **disjoint**, then \\( P(A \cap B) = 0 \\)
- But that contradicts \\( P(A) \cdot P(B) > 0 \\) â€” so:
> **Disjoint events are always dependent.**  
> **Independent events are never disjoint (unless one has probability 0).**

---

## ğŸ§ª <span style="color:#20B2AA;">Example: Email Spam Detection</span>

Suppose:
- 40% of all emails are spam â†’ \\( P(S) = 0.4 \\)
- 80% of spam emails contain the word â€œfreeâ€ â†’ \\( P(F \mid S) = 0.8 \\)
- 10% of non-spam emails contain â€œfreeâ€ â†’ \\( P(F \mid \bar{S}) = 0.1 \\)

---

## ğŸŒ³ <span style="color:#228B22;">Build a Decision Tree</span>


![Bayes Decision Tree](/assets/images/bayes_decision_tree.png)
*Figure: Tree diagram showing all outcomes for Spam vs Free*


We can calculate all joint probabilities:

- \\( P(S \cap F) = 0.4 \cdot 0.8 = 0.32 \\)  
- \\( P(\bar{S} \cap F) = 0.6 \cdot 0.1 = 0.06 \\)  
- \\( P(F) = 0.32 + 0.06 = 0.38 \\)

---

## ğŸ“˜ <span style="color:#8A2BE2;">Bayes' Theorem</span>

Now, we want:

> If I see â€œfreeâ€ in an email, whatâ€™s the probability itâ€™s spam?

### ğŸ“Œ Formula:
\\[
P(S \mid F) = \frac{P(S \cap F)}{P(F)} = \frac{0.32}{0.38} \approx 0.842
\\]

---

## ğŸ§  <span style="color:#9370DB;">Understanding Bayes' Rule: Components</span>

| Term           | Meaning                                                                |
| -------------- | ---------------------------------------------------------------------- |
| **Prior**      | What you believe before seeing the evidence â†’ \\( P(S) = 0.4 \\)       |
| **Likelihood** | Probability of the evidence given the hypothesis â†’ \\( P(F \mid S) \\) |
| **Evidence**   | Total probability of seeing â€œfreeâ€ â†’ \\( P(F) = 0.38 \\)               |
| **Posterior**  | Updated belief â†’ \\( P(S \mid F) = 0.842 \\)                           |

---

## ğŸ§  Bayesâ€™ Theorem in Action: Two Real-World Examples

---

### ğŸ“š Example 1: Student Cheating Detection

A teacher knows that only **2% of students** cheat on exams.

She uses a plagiarism detector that:
- Correctly identifies cheaters 90% of the time  
- Wrongly flags innocent students 5% of the time

Now, a student gets flagged. What are the chances they actually cheated?

Let:
- \\( C \\): student cheated
- \\( P \\): student flagged

We know:
- \\( P(C) = 0.02 \\),â€ƒâ€ƒ\\( P(\bar{C}) = 0.98 \\)  
- \\( P(P \mid C) = 0.90 \\)  
- \\( P(P \mid \bar{C}) = 0.05 \\)

---

### âœï¸ Bayes' Theorem:

\\[
P(C \mid P) = \frac{P(P \mid C) \cdot P(C)}{P(P \mid C) \cdot P(C) + P(P \mid \bar{C}) \cdot P(\bar{C})}
\\]

#### ğŸ” Interpretation:
- **Numerator** = Likelihood Ã— Prior = \\( 0.90 \cdot 0.02 = 0.018 \\)  
  â†’ This is the **joint probability** of being a cheater **and** being flagged
- **Denominator** = Total probability of being flagged  
  â†’ Includes both cheaters and non-cheaters who were flagged:
\\[
= 0.018 + (0.05 \cdot 0.98) = 0.018 + 0.049 = 0.067
\\]

### âœ… Final Answer:
\\[
P(C \mid P) = \frac{0.018}{0.067} \approx 0.268
\\]

Even if flagged, there's only a **~26.8% chance** the student actually cheated.

![Bayes Pie Chart](/assets/images/bayes_pie_chart.png)
*Figure: True vs False Positives that make up the total evidence (P(Flagged))*


---

### ğŸ’Š Example 2: Random Drug Testing at Work

A company screens employees for a rare performance-enhancing drug.

- Only **1 in 1,000** uses it â†’ \\( P(D) = 0.001 \\)
- The test is **99% accurate**:
  - \\( P(+ \mid D) = 0.99 \\)  
  - \\( P(+ \mid \bar{D}) = 0.01 \\)

An employee tests positive. What's the probability they actually use the drug?

---

### âœï¸ Bayes' Theorem:

\\[
P(D \mid +) = \frac{P(+ \mid D) \cdot P(D)}{P(+ \mid D) \cdot P(D) + P(+ \mid \bar{D}) \cdot P(\bar{D})}
\\]

#### ğŸ” Interpretation:
- **Numerator** = Likelihood Ã— Prior = \\( 0.99 \cdot 0.001 = 0.00099 \\)  
  â†’ This is the **joint probability** of actually using the drug and testing positive
- **Denominator** = Total probability of testing positive:
\\[
= 0.00099 + (0.01 \cdot 0.999) = 0.00099 + 0.00999 = 0.01098
\\]

### âœ… Final Answer:
\\[
P(D \mid +) = \frac{0.00099}{0.01098} \approx 0.09
\\]

Despite a positive result, there's only a **~9% chance** the employee actually uses the drug â€” because the condition is rare, and **false positives dominate** the denominator.

---
![Bayes Formula Flow](/assets/images/bayes_formula_flow.png)
*Figure: Flow of belief update â€” from prior and likelihood to posterior*


---

<details class="level-up-box">
   <summary class="level-up-title"><strong>ğŸ§  Level Up: Mastering Bayes â€” Whatâ€™s Really Going On?</strong></summary>
<div class="level-up-content">
    <p>Bayesâ€™ Theorem might look like a formula â€” but itâ€™s actually a way of <strong>reversing conditional logic</strong>.</p>

    <ul>
      <li>ğŸ¯ The <strong>numerator</strong> is the probability that <em>both the hypothesis and evidence</em> are true (joint probability).</li>
      <li>ğŸ§ª The <strong>denominator</strong> is the <em>total probability</em> of the observed evidence â€” from all possible sources.</li>
    </ul>

    <p>So Bayesâ€™ Theorem simply asks:</p>
    <blockquote class="blockquote">
      If this result just happened, how likely was it caused by what I suspected?
    </blockquote>

    <p>ğŸ§  Youâ€™re updating your belief (the prior) based on what you just saw (the evidence), and how likely that evidence is under each possible explanation (likelihood).</p>

    <p><strong>Bayes is not just math â€” itâ€™s decision logic under uncertainty.</strong></p>
  </div>
</details>

---
<details class="custom-box custom-best">
  <summary><strong>âœ… Best Practices for Bayesâ€™ Rule</strong></summary>
  <ul>
    <li>Understand the difference between prior, likelihood, and posterior before applying the formula.</li>
    <li>Use tree diagrams or tables to break down problems clearly.</li>
    <li>Double-check that your events are independent when assuming so.</li>
    <li>Always compute total probability in the denominator correctly.</li>
  </ul>
</details>
---
<details class="custom-box custom-warning">
  <summary><strong>âš ï¸ Common Pitfalls</strong></summary>
  <ul>
    <li>âŒ Confusing <strong>P(A | B)</strong> with <strong>P(B | A)</strong>.</li>
    <li>âŒ Ignoring base rates (priors), especially when they are very small.</li>
    <li>âŒ Mislabeling dependent events as independent.</li>
    <li>âŒ Forgetting to normalize with the full evidence probability in the denominator.</li>
  </ul>
</details>

---
{% include quiz/Bayes.html %}

---

## ğŸ§  Summary

| Concept             | Meaning                                     |
| ------------------- | ------------------------------------------- |
| Independence        | One event does not affect the other         |
| Disjoint            | Events canâ€™t happen together                |
| Joint from Marginal | Only possible if events are independent     |
| Bayes' Rule         | Updates belief with new data                |
| Prior               | Initial belief                              |
| Likelihood          | How likely the data is under a hypothesis   |
| Posterior           | Updated probability                         |
| Evidence            | Total probability of the observed condition |

---

## ğŸ’¬ Got a question or suggestion?

Leave a comment below â€” Iâ€™d love to hear your thoughts or help if something was unclear.

---
## âœ… Up Next

Next, weâ€™ll dive into **probability distributions** and how cumulative distributions help us model real-world events over time.

Stay tuned!
